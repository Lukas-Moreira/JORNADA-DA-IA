# Cap√≠tulo 3: Treinamento de Redes Neurais üß†

## üßÆ Fun√ß√£o de Custo e Aprendizado

Para que uma rede neural aprenda, √© necess√°rio medir a precis√£o de suas previs√µes. Isso √© feito atrav√©s de uma **fun√ß√£o de custo** (ou **fun√ß√£o de perda**), que avalia o quanto a sa√≠da da rede difere do valor real esperado.

Quanto menor o valor da fun√ß√£o de custo, melhor o desempenho da rede.

Essas fun√ß√µes orientam o aprendizado da rede, indicando **como os pesos devem ser ajustados** para minimizar o erro.

---

### üìä Principais Fun√ß√µes de Custo

- **Erro Quadr√°tico M√©dio (Mean Squared Error - MSE)**  
  Usado em tarefas de regress√£o.  
  Calcula a m√©dia dos quadrados das diferen√ßas entre as previs√µes e os valores reais.

- **Entropia Cruzada (Cross-Entropy)**  
  Usada em tarefas de classifica√ß√£o.  
  Mede a diferen√ßa entre duas distribui√ß√µes probabil√≠sticas: a previs√£o e o r√≥tulo real.  
  - Para classifica√ß√£o bin√°ria, √© amplamente utilizada por sua efic√°cia.

- **Erro Absoluto M√©dio (Mean Absolute Error - MAE)**  
  Calcula a m√©dia das diferen√ßas absolutas entre as previs√µes e os valores reais.  
  √â menos sens√≠vel a outliers do que o MSE.

---

## üîÅ Retropropaga√ß√£o (Backpropagation)

A **retropropaga√ß√£o** √© o algoritmo respons√°vel por **ajustar os pesos da rede** para minimizar a fun√ß√£o de custo. Esse processo ocorre em duas etapas:

1. **Propaga√ß√£o Direta (Forward Propagation)**  
   A entrada percorre a rede at√© a sa√≠da, onde √© feita a previs√£o.

2. **Retropropaga√ß√£o**  
   A partir do erro calculado, os **pesos s√£o ajustados** no sentido de reduzir esse erro, utilizando o gradiente da fun√ß√£o de custo.

---

## ‚öôÔ∏è Otimiza√ß√£o

O processo de ajuste dos pesos √© realizado por **algoritmos de otimiza√ß√£o**. O mais b√°sico √© o **Gradiente Descendente**, mas existem vers√µes mais avan√ßadas:

- **SGD (Stochastic Gradient Descent)**  
  Atualiza os pesos com base em um √∫nico exemplo ou mini-batch.  
  √â mais r√°pido em grandes conjuntos de dados, mas pode apresentar oscila√ß√µes.

- **Adam (Adaptive Moment Estimation)**  
  Combina m√©todos de momento e adapta√ß√£o de taxa de aprendizado.  
  √â amplamente utilizado por sua **efici√™ncia e estabilidade**, principalmente em redes profundas.

- **RMSprop (Root Mean Square Propagation)**  
  Ajusta a taxa de aprendizado com base nos gradientes recentes.  
  √â √∫til em cen√°rios com fun√ß√µes de custo ruidosas.

---

## üõ°Ô∏è Regulariza√ß√£o e Overfitting

**Overfitting** ocorre quando a rede aprende muito bem os dados de treino, mas n√£o consegue generalizar para novos dados. Algumas t√©cnicas ajudam a evitar esse problema:

- **Dropout**  
  Durante o treinamento, desativa aleatoriamente alguns neur√¥nios em cada itera√ß√£o, for√ßando a rede a aprender representa√ß√µes mais robustas.

- **Regulariza√ß√£o L2**  
  Penaliza pesos muito grandes adicionando um termo √† fun√ß√£o de custo, ajudando a reduzir a complexidade da rede.

- **Early Stopping**  
  Monitora a fun√ß√£o de custo em um conjunto de valida√ß√£o e **interrompe o treinamento** quando o desempenho come√ßa a piorar, prevenindo overfitting.

---
üìÅ *Este conte√∫do faz parte da minha jornada de estudos em IA, com experimentos pr√°ticos implementados em Python e frameworks como TensorFlow.*